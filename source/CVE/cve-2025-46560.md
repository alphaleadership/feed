---
title: CVE-2025-46560
date: [[2025]]-4-30
lien: "https://cvefeed.io/vuln/detail/CVE-2025-46560"

---

CVE ID : CVE-2025-46560

Published :  April 30
2025
1:15 a.m. | 1 hour
20 minutes ago

Description : vLLM is a high-throughput and memory-efficient inference and serving engine for [[LLM]]s. Versions starting from 0.8.0 and prior to 0.8.5 are affected by a critical performance vulnerability in the input preprocessing logic of the multimodal [[token]]izer. The code dynamically replaces placeholder [[token]]s (e.g.

) with repeated [[token]]s based on precomputed lengths. Due to ​​inefficient list concatenation operations​​
the algorithm exhibits ​​quadratic time complexity (O(n²))​​
allowing malicious actors to trigger resource exhaustion via specially [[crafted]] inputs. This issue has been patched in version 0.8.5.

Severity: 6.5 | MEDIUM

Visit the link for more details
such as CVSS details
affected products
timeline
and more...
